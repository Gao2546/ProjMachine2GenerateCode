{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import requests\n",
    "import csv\n",
    "import time\n",
    "import re\n",
    "import urllib\n",
    "import json\n",
    "import numpy as np\n",
    "import threading\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import cloudscraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f\"link_data_stack_overflow_python_1981285.pickle\", \"rb\") as f:\n",
    "#     all_link = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f\"link_data_stack_overflow_python_0_200000.pickle\", \"wb\") as f:\n",
    "#     pickle.dump(all_link[:200000],f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f\"link_data_stack_overflow_python_200000_400000.pickle\", \"wb\") as f:\n",
    "#     pickle.dump(all_link[200000:400000],f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f\"link_data_stack_overflow_python_400000_600000.pickle\", \"wb\") as f:\n",
    "#     pickle.dump(all_link[400000:600000],f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f\"link_data_stack_overflow_python_600000_800000.pickle\", \"wb\") as f:\n",
    "#     pickle.dump(all_link[600000:800000],f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f\"link_data_stack_overflow_python_800000_1000000.pickle\", \"wb\") as f:\n",
    "#     pickle.dump(all_link[800000:1000000],f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"../use_link_load_data_0_1000000/link_data_stack_overflow_python_0_200000.pickle\", \"rb\") as f:\n",
    "    save_link = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(save_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pages = len(save_link)\n",
    "count_thread = 80\n",
    "per_vm = 8\n",
    "vm_number = 1\n",
    "num_per_thread = max_pages//count_thread\n",
    "page_last = max_pages%count_thread\n",
    "all_thread = [None]*count_thread\n",
    "code_question = [None]*count_thread\n",
    "code_answer = [None]*count_thread\n",
    "webs = \"https://stackoverflow.com/\"\n",
    "hours = 10\n",
    "minute = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_code_question_answer_all_data(code_question,code_answer,start,stop,number_thread):\n",
    "    try:\n",
    "        scraper = cloudscraper.create_scraper(delay=10,browser=\"chrome\")\n",
    "        st = time.time()\n",
    "        if (code_question[number_thread] or code_answer[number_thread]) != None:\n",
    "            code_answer_in_link = code_answer[number_thread][:start]\n",
    "            code_question_in_link = code_question[number_thread][:start]\n",
    "        else:\n",
    "            code_answer_in_link = []\n",
    "            code_question_in_link = []\n",
    "\n",
    "        replace_code = [['<code>',''],['</code>',''],['&lt;','<'],['&gt;','>'],['&amp;','&'],['&quot;','\"'],['&apos;',\"'\"],['>>> ',''],['... ',''],['...','']]\n",
    "        count = start\n",
    "        for question_link in save_link[start:stop]:\n",
    "            if (time.time() - st) > (hours*60 + minute)*60:\n",
    "                print(f\"-->threading : {number_thread+1}\\nlink : {count} finish with time stop hours : {hours} minute : {minute}\\n{'*'*20}\")\n",
    "                return 0\n",
    "            url_page = webs + question_link\n",
    "            #------------------------------------\n",
    "            while True:\n",
    "                while True:\n",
    "                    res_page = scraper.get(url_page)\n",
    "                    if res_page.ok:\n",
    "                        #print(f\"Thread : {number_thread} page open\")\n",
    "                        break\n",
    "                html_page = res_page.text\n",
    "                soup_page = BeautifulSoup(html_page ,features=\"html.parser\")\n",
    "                #------------------------------------\n",
    "                if len(soup_page.find_all('a',{'class':'s-pagination--item'}))/2 > 1:\n",
    "                    last_page = soup_page.find_all('a',{'class':'s-pagination--item'})[-2].text\n",
    "                else :last_page = 1\n",
    "                code_question_reg = [str(soup_page.find_all('a',{'class':'question-hyperlink'})[0].text)]\n",
    "                if soup_page.find_all('a',{'class':'question-hyperlink'})[0].text != None:\n",
    "                    code_question_in_link.append(code_question_reg)\n",
    "                    break\n",
    "            answer = []\n",
    "                #------------------------------------\n",
    "            for page_in_question_link in range(int(last_page)):\n",
    "                url_page = webs + question_link + f\"?page={page_in_question_link+1}&tab=scoredesc#tab-top\"\n",
    "                while True:\n",
    "                    while True:\n",
    "                        res_page = scraper.get(url_page)\n",
    "                        if res_page.ok:\n",
    "                            #print(f\"Thread : {number_thread} page open\")\n",
    "                            break\n",
    "                    html_page = res_page.text\n",
    "                    soup_page = BeautifulSoup(html_page ,features=\"html.parser\")\n",
    "\n",
    "                    answer_s = soup_page.find_all('div',{'id':'answers'})\n",
    "                    # answer = soup_page.find_all('div',{'class':'s-prose'},{'class':'js-post-body'},{'id':'answers'})\n",
    "                    # for i_answer in answer:\n",
    "                    #     for i_code in i_answer.find_all('code'):\n",
    "                    #         if len(str(i_code)) > 50:\n",
    "                    #             i_code = str(i_code)\n",
    "                    #             for rep in replace_code:\n",
    "                    #                 i_code = i_code.replace(rep[0],rep[1])\n",
    "                    #             # code_answer.append((((str(i_code).replace('<code>','')).replace('</code>','')).replace('&gt;&gt;&gt; ','')).replace('... ',''))\n",
    "                    #             code_answer.append(i_code)\n",
    "                    if answer_s != None:\n",
    "                        answer.append(answer_s[0])#*************************\n",
    "\n",
    "            code_answer_in_link.append(answer)#**************************\n",
    "            count += 1\n",
    "            if count%50==0:\n",
    "                print(f\"threading : {number_thread+1}\\nlink : {count}\\nprogress : {((count-start+1)/(stop-start))*100:.2f}%\\n{'*'*20}\")\n",
    "        code_answer[number_thread] = code_answer_in_link\n",
    "        code_question[number_thread] = code_question_in_link\n",
    "        print(f\"-->threading : {number_thread+1}\\nlink : {count} finish\\n{'*'*20}\")\n",
    "    except:\n",
    "        code_answer[number_thread] = code_answer_in_link\n",
    "        code_question[number_thread] = code_question_in_link\n",
    "        print(f\"-->threading : {number_thread+1}\\nlink : {count} loop_interrup_finish\\n{'*'*20}\")\n",
    "        save_code_question_answer_all_data(code_question,code_answer,count,stop,number_thread)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = (page_last - 1)\n",
    "for i in range(vm_number*per_vm,(vm_number+1)*per_vm):\n",
    "    if i < page_last:\n",
    "        all_thread[i] = threading.Thread(target=save_code_question_answer_all_data,args=(all_link,all_status_link,i*num_per_thread + i*(1),(i+1)*num_per_thread + (i+1)*1,i))\n",
    "        print(i*num_per_thread + i*(1),(i+1)*num_per_thread + (i+1)*1,i)\n",
    "    elif page_last == 0:\n",
    "        all_thread[i] = threading.Thread(target=save_code_question_answer_all_data,args=(all_link,all_status_link,i*num_per_thread,(i+1)*num_per_thread,i))\n",
    "        print(i*num_per_thread,(i+1)*num_per_thread,i)\n",
    "    else:\n",
    "        all_thread[i] = threading.Thread(target=save_code_question_answer_all_data,args=(all_link,all_status_link,i*num_per_thread + (li+1)*(1),(i+1)*num_per_thread + (li+1)*1,i))\n",
    "        print(i*num_per_thread + (li+1)*(1),(i+1)*num_per_thread + (li+1)*1,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(vm_number*per_vm,(vm_number+1)*per_vm):\n",
    "    all_thread[i].start()\n",
    "for i in range(vm_number*per_vm,(vm_number+1)*per_vm):\n",
    "    all_thread[i].join()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
