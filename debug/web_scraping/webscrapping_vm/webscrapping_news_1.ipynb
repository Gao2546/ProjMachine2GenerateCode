{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install cloudscraper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "M9jDK2uNKHtm"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "from urllib.request import urlopen\n",
        "import requests\n",
        "import csv\n",
        "import time\n",
        "import re\n",
        "import urllib\n",
        "import json\n",
        "import numpy as np\n",
        "import threading\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "import cloudscraper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKvBYak5Lrf2"
      },
      "source": [
        "#Collect link form web stack overflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GWS8SktvLxY4"
      },
      "outputs": [],
      "source": [
        "# beauty_soup.py\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.request import urlopen\n",
        "import requests\n",
        "\n",
        "pages = 1\n",
        "url = f\"https://stackoverflow.com/questions/tagged/python?tab=votes&page={pages}&pagesize=50\"\n",
        "url = \"https://stackoverflow.com/questions/tagged/python?tab=Newest\"\n",
        "scraper = cloudscraper.create_scraper(delay=10,browser=\"chrome\")\n",
        "res = scraper.get(url)\n",
        "html = res.text\n",
        "#page = urlopen(url)\n",
        "#html = page.read().decode(\"utf-8\")\n",
        "soup = BeautifulSoup(html, \"html.parser\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad3kNcCPPYJH",
        "outputId": "b8b754ca-f759-4fb9-8f5e-627121d55395"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<a class=\"s-pagination--item js-pagination-item\" href=\"/questions/tagged/python?tab=newest&amp;page=2&amp;pagesize=15\" rel=\"\" title=\"Go to page 2\">2</a>,\n",
              " <a class=\"s-pagination--item js-pagination-item\" href=\"/questions/tagged/python?tab=newest&amp;page=3&amp;pagesize=15\" rel=\"\" title=\"Go to page 3\">3</a>,\n",
              " <a class=\"s-pagination--item js-pagination-item\" href=\"/questions/tagged/python?tab=newest&amp;page=4&amp;pagesize=15\" rel=\"\" title=\"Go to page 4\">4</a>,\n",
              " <a class=\"s-pagination--item js-pagination-item\" href=\"/questions/tagged/python?tab=newest&amp;page=5&amp;pagesize=15\" rel=\"\" title=\"Go to page 5\">5</a>,\n",
              " <a class=\"s-pagination--item js-pagination-item\" href=\"/questions/tagged/python?tab=newest&amp;page=145393&amp;pagesize=15\" rel=\"\" title=\"Go to page 145393\">145393</a>,\n",
              " <a class=\"s-pagination--item js-pagination-item\" href=\"/questions/tagged/python?tab=newest&amp;page=2&amp;pagesize=15\" rel=\"next\" title=\"Go to page 2\"> Next</a>]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "soup.find_all('a',{'class':'s-pagination--item js-pagination-item'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d1XfcL2O5XL",
        "outputId": "b21c1192-d154-4060-c4e4-9d70084552e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(soup.find_all('a',{'class':'s-pagination--item js-pagination-item'})) == 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Gym05ydjMEUj"
      },
      "outputs": [],
      "source": [
        "# max_pages = int(soup.find_all('a',{'class':'s-pagination--item js-pagination-item'})[-2].text)\n",
        "# # max_pages = 43654\n",
        "# count_thread = 16\n",
        "# num_per_thread = max_pages//16\n",
        "# page_last = max_pages%16\n",
        "# all_thread = [None]*count_thread\n",
        "# all_link = [None]*count_thread\n",
        "# all_status_link = [None]*count_thread"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DBHBHKK7EwuW"
      },
      "outputs": [],
      "source": [
        "max_pages = 43645\n",
        "count_thread = 80\n",
        "per_vm = 8\n",
        "vm_number = 1\n",
        "num_per_thread = max_pages//count_thread\n",
        "page_last = max_pages%count_thread\n",
        "all_thread = [None]*count_thread\n",
        "all_link = [None]*count_thread\n",
        "all_status_link = [None]*count_thread"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "545"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "num_per_thread"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "45"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "page_last"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4C8fqzvFMOmC"
      },
      "outputs": [],
      "source": [
        "# def find_all_link(all_link,start,stop,number_thread):\n",
        "#     #print(f\"start thread : {number_thread+1}\\nstart_page : {start}\\nstop_page : {stop-1}\\n{'*'*20}\")\n",
        "#     try:\n",
        "#         if all_link[number_thread] != None:\n",
        "#             all_link_thread = all_link[number_thread][:start]\n",
        "#         else:\n",
        "#             all_link_thread = []\n",
        "#         pages = start\n",
        "#         for pages in range(start,stop):\n",
        "#           while True:\n",
        "#               url = f\"https://stackoverflow.com/questions/tagged/python?tab=votes&page={pages+1}&pagesize=50\"\n",
        "#               while True :\n",
        "#                 scraper = cloudscraper.create_scraper(delay=10,browser=\"chrome\")\n",
        "#                 res = scraper.get(url)\n",
        "#                 if res.ok:\n",
        "#                     break\n",
        "#               html = res.text\n",
        "#               #page = urlopen(url)\n",
        "#               #html = page.read().decode(\"utf-8\")\n",
        "#               soup = BeautifulSoup(html, \"html.parser\")\n",
        "#               if len(soup.find_all('h3',{'class':'s-post-summary--content-title'},{'id':'questions'})) == 0:\n",
        "#                 print(\"sleep\")\n",
        "#                 time.sleep(0.1)\n",
        "#               else:\n",
        "#                 break\n",
        "#           for c in soup.find_all('h3',{'class':'s-post-summary--content-title'},{'id':'questions'}):\n",
        "#               ss = c.find_all('a',{'class':'s-link'})\n",
        "#               all_link_thread.append(ss[0][\"href\"])\n",
        "#               #print(ss)\n",
        "#           if pages%50==0:\n",
        "#               print(f\"threading : {number_thread+1}\\npage : {pages+1}\\nprogress : {((pages-start+1)/(stop-start))*100:.2f}%\\n{'*'*20}\")\n",
        "#         all_link[number_thread] = all_link_thread\n",
        "#         print(f\"-->threading : {number_thread+1}\\npage : {pages+1} finish\\n{'*'*20}\")\n",
        "#     except:\n",
        "#         all_link[number_thread] = all_link_thread\n",
        "#         print(f\"-->threading : {number_thread+1}\\npage : {pages+1} loop_interrup_finish\\n{'*'*20}\")\n",
        "#         print(\"cont_restart\")\n",
        "#         find_all_link(all_link,pages,stop,number_thread)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "1K9KOy07aJde"
      },
      "outputs": [],
      "source": [
        "def find_all_link(all_link,all_status_link,start,stop,number_thread):\n",
        "    #print(f\"start thread : {number_thread+1}\\nstart_page : {start}\\nstop_page : {stop-1}\\n{'*'*20}\")\n",
        "    try:\n",
        "        scraper = cloudscraper.create_scraper(delay=10,browser=\"chrome\")\n",
        "        if all_link[number_thread] != None:\n",
        "            all_link_thread = all_link[number_thread][:start]\n",
        "            all_status_link_thread = all_status_link[number_thread][:start]\n",
        "        else:\n",
        "            all_link_thread = []\n",
        "            all_status_link_thread = []\n",
        "        pages = start\n",
        "        for pages in range(start,stop):\n",
        "            while True:\n",
        "                url = f\"https://stackoverflow.com/questions/tagged/python?tab=votes&page={pages+1}&pagesize=50\"\n",
        "                while True :\n",
        "                    res = scraper.get(url)\n",
        "                    if res.ok:\n",
        "                        break\n",
        "                html = res.text\n",
        "                #page = urlopen(url)\n",
        "                #html = page.read().decode(\"utf-8\")\n",
        "                soup = BeautifulSoup(html, \"html.parser\")\n",
        "                if len(soup.find_all('h3',{'class':'s-post-summary--content-title'},{'id':'questions'})) == 0:\n",
        "                    print(\"sleep\")\n",
        "                    time.sleep(0.1)\n",
        "                else:\n",
        "                    break\n",
        "            for c in soup.find_all('h3',{'class':'s-post-summary--content-title'},{'id':'questions'}):\n",
        "                ss = c.find_all('a',{'class':'s-link'})\n",
        "                all_link_thread.append(ss[0][\"href\"])\n",
        "\n",
        "            for d_status in soup.find_all('div',{'class':'s-post-summary--stats js-post-summary-stats'}):\n",
        "                dd_status = [status.text for status in d_status.find_all('span',{'class':'s-post-summary--stats-item-number'})]\n",
        "                all_status_link_thread.append(dd_status)\n",
        "            if pages%50==0:\n",
        "                print(f\"threading : {number_thread+1}\\npage : {pages+1}\\nprogress : {((pages-start+1)/(stop-start))*100:.2f}%\\n{'*'*20}\")\n",
        "        all_link[number_thread] = all_link_thread\n",
        "        all_status_link[number_thread] = all_status_link_thread\n",
        "        print(f\"-->threading : {number_thread+1}\\npage : {pages+1} finish\\n{'*'*20}\")\n",
        "    except:\n",
        "        all_link[number_thread] = all_link_thread\n",
        "        all_status_link[number_thread] = all_status_link_thread\n",
        "        print(f\"-->threading : {number_thread+1}\\npage : {pages+1} loop_interrup_finish\\n{'*'*20}\")\n",
        "        print(\"cont_restart\")\n",
        "        find_all_link(all_link,all_status_link,pages,stop,number_thread)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuSFl_zWMR53",
        "outputId": "7393176e-bdef-4dce-89a6-e660fdd71746"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4368 4914 8\n",
            "4914 5460 9\n",
            "5460 6006 10\n",
            "6006 6552 11\n",
            "6552 7098 12\n",
            "7098 7644 13\n",
            "7644 8190 14\n",
            "8190 8736 15\n"
          ]
        }
      ],
      "source": [
        "li = (page_last - 1)\n",
        "for i in range(vm_number*per_vm,(vm_number+1)*per_vm):\n",
        "    if i < page_last:\n",
        "        all_thread[i] = threading.Thread(target=find_all_link,args=(all_link,all_status_link,i*num_per_thread + i*(1),(i+1)*num_per_thread + (i+1)*1,i))\n",
        "        print(i*num_per_thread + i*(1),(i+1)*num_per_thread + (i+1)*1,i)\n",
        "    elif page_last == 0:\n",
        "        all_thread[i] = threading.Thread(target=find_all_link,args=(all_link,all_status_link,i*num_per_thread,(i+1)*num_per_thread,i))\n",
        "        print(i*num_per_thread,(i+1)*num_per_thread,i)\n",
        "    else:\n",
        "        all_thread[i] = threading.Thread(target=find_all_link,args=(all_link,all_status_link,i*num_per_thread + (li+1)*(1),(i+1)*num_per_thread + (li+1)*1,i))\n",
        "        print(i*num_per_thread + (li+1)*(1),(i+1)*num_per_thread + (li+1)*1,i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCmHLWxoMUXZ",
        "outputId": "635f79f6-4bd6-4dd6-cf9e-bdd7d29afdae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "threading : 51\n",
            "page : 9751\n",
            "progress : 0.51%\n",
            "********************\n",
            "threading : 61\n",
            "page : 11701\n",
            "progress : 0.51%\n",
            "********************\n",
            "threading : 52\n",
            "page : 9951\n",
            "progress : 3.08%\n",
            "********************\n",
            "threading : 62\n",
            "page : 11901\n",
            "progress : 3.08%\n",
            "********************\n",
            "threading : 64\n",
            "page : 12301\n",
            "progress : 8.21%\n",
            "********************\n",
            "threading : 63\n",
            "page : 12101\n",
            "progress : 5.64%\n",
            "********************\n",
            "threading : 53\n",
            "page : 10151\n",
            "progress : 5.64%\n",
            "********************\n",
            "threading : 54\n",
            "page : 10351\n",
            "progress : 8.21%\n",
            "********************\n",
            "threading : 55\n",
            "page : 10551\n",
            "progress : 10.77%\n",
            "********************\n",
            "threading : 56\n",
            "page : 10751\n",
            "progress : 13.33%\n",
            "********************\n",
            "threading : 57\n",
            "page : 10951\n",
            "progress : 15.90%\n",
            "********************\n",
            "threading : 58\n",
            "page : 11151\n",
            "progress : 18.46%\n",
            "********************\n",
            "threading : 49\n",
            "page : 9401\n",
            "progress : 21.03%\n",
            "********************\n",
            "threading : 59\n",
            "page : 11351\n",
            "progress : 21.03%\n",
            "********************\n",
            "threading : 60\n",
            "page : 11551\n",
            "progress : 23.59%\n",
            "********************\n",
            "threading : 51\n",
            "page : 9801\n",
            "progress : 26.15%\n",
            "********************\n",
            "threading : 64\n",
            "page : 12351\n",
            "progress : 33.85%\n",
            "********************\n",
            "threading : 61\n",
            "page : 11751\n",
            "progress : 26.15%\n",
            "********************\n",
            "threading : 62\n",
            "page : 11951\n",
            "progress : 28.72%\n",
            "********************\n",
            "threading : 50\n",
            "page : 9601\n",
            "progress : 23.59%\n",
            "********************\n",
            "threading : 52\n",
            "page : 10001\n",
            "progress : 28.72%\n",
            "********************\n",
            "threading : 63\n",
            "page : 12151\n",
            "progress : 31.28%\n",
            "********************\n",
            "threading : 53\n",
            "page : 10201\n",
            "progress : 31.28%\n",
            "********************\n",
            "threading : 56\n",
            "page : 10801\n",
            "progress : 38.97%\n",
            "********************\n",
            "threading : 54\n",
            "page : 10401\n",
            "progress : 33.85%\n",
            "********************\n",
            "threading : 55\n",
            "page : 10601\n",
            "progress : 36.41%\n",
            "********************\n",
            "threading : 57\n",
            "page : 11001\n",
            "progress : 41.54%\n",
            "********************\n",
            "threading : 49\n",
            "page : 9451\n",
            "progress : 46.67%\n",
            "********************\n",
            "threading : 58\n",
            "page : 11201\n",
            "progress : 44.10%\n",
            "********************\n",
            "threading : 59\n",
            "page : 11401\n",
            "progress : 46.67%\n",
            "********************\n",
            "threading : 64\n",
            "page : 12401\n",
            "progress : 59.49%\n",
            "********************\n",
            "threading : 61\n",
            "page : 11801\n",
            "progress : 51.79%\n",
            "********************\n",
            "threading : 63\n",
            "page : 12201\n",
            "progress : 56.92%\n",
            "********************\n",
            "threading : 50\n",
            "page : 9651\n",
            "progress : 49.23%\n",
            "********************\n",
            "threading : 51\n",
            "page : 9851\n",
            "progress : 51.79%\n",
            "********************\n",
            "threading : 52\n",
            "page : 10051\n",
            "progress : 54.36%\n",
            "********************\n",
            "threading : 62\n",
            "page : 12001\n",
            "progress : 54.36%\n",
            "********************\n",
            "threading : 53\n",
            "page : 10251\n",
            "progress : 56.92%\n",
            "********************\n",
            "threading : 55\n",
            "page : 10651\n",
            "progress : 62.05%\n",
            "********************\n",
            "threading : 60\n",
            "page : 11601\n",
            "progress : 49.23%\n",
            "********************\n",
            "threading : 56\n",
            "page : 10851\n",
            "progress : 64.62%\n",
            "********************\n",
            "threading : 54\n",
            "page : 10451\n",
            "progress : 59.49%\n",
            "********************\n",
            "threading : 57\n",
            "page : 11051\n",
            "progress : 67.18%\n",
            "********************\n",
            "threading : 49\n",
            "page : 9501\n",
            "progress : 72.31%\n",
            "********************\n",
            "threading : 59\n",
            "page : 11451\n",
            "progress : 72.31%\n",
            "********************\n",
            "threading : 61\n",
            "page : 11851\n",
            "progress : 77.44%\n",
            "********************\n",
            "threading : 63\n",
            "page : 12251\n",
            "progress : 82.56%\n",
            "********************\n",
            "threading : 60\n",
            "page : 11651\n",
            "progress : 74.87%\n",
            "********************\n",
            "threading : 58\n",
            "page : 11251\n",
            "progress : 69.74%\n",
            "********************\n",
            "threading : 51\n",
            "page : 9901\n",
            "progress : 77.44%\n",
            "********************\n",
            "threading : 50\n",
            "page : 9701\n",
            "progress : 74.87%\n",
            "********************\n",
            "threading : 62\n",
            "page : 12051\n",
            "progress : 80.00%\n",
            "********************\n",
            "threading : 56\n",
            "page : 10901\n",
            "progress : 90.26%\n",
            "********************\n",
            "threading : 52\n",
            "page : 10101\n",
            "progress : 80.00%\n",
            "********************\n",
            "threading : 64\n",
            "page : 12451\n",
            "progress : 85.13%\n",
            "********************\n",
            "threading : 53\n",
            "page : 10301\n",
            "progress : 82.56%\n",
            "********************\n",
            "threading : 55\n",
            "page : 10701\n",
            "progress : 87.69%\n",
            "********************\n",
            "threading : 57\n",
            "page : 11101\n",
            "progress : 92.82%\n",
            "********************\n",
            "-->threading : 56\n",
            "page : 10920 finish\n",
            "********************\n",
            "threading : 54\n",
            "page : 10501\n",
            "progress : 85.13%\n",
            "********************\n",
            "-->threading : 63\n",
            "page : 12285 finish\n",
            "********************\n",
            "threading : 49\n",
            "page : 9551\n",
            "progress : 97.95%\n",
            "********************\n",
            "-->threading : 55\n",
            "page : 10725 finish\n",
            "********************\n",
            "-->threading : 57\n",
            "page : 11115 finish\n",
            "********************\n",
            "-->threading : 64\n",
            "page : 12480 finish\n",
            "********************\n",
            "-->threading : 49\n",
            "page : 9555 finish\n",
            "********************\n",
            "-->threading : 61\n",
            "page : 11895 finish\n",
            "********************\n",
            "-->threading : 62\n",
            "page : 12090 finish\n",
            "********************\n",
            "threading : 59\n",
            "page : 11501\n",
            "progress : 97.95%\n",
            "********************\n",
            "-->threading : 53\n",
            "page : 10335 finish\n",
            "********************\n",
            "-->threading : 52\n",
            "page : 10140 finish\n",
            "********************\n",
            "-->threading : 60\n",
            "page : 11700 finish\n",
            "********************\n",
            "-->threading : 50\n",
            "page : 9750 finish\n",
            "********************\n",
            "-->threading : 51\n",
            "page : 9945 finish\n",
            "********************\n",
            "-->threading : 54\n",
            "page : 10530 finish\n",
            "********************\n",
            "-->threading : 59\n",
            "page : 11505 finish\n",
            "********************\n",
            "threading : 58\n",
            "page : 11301\n",
            "progress : 95.38%\n",
            "********************\n",
            "-->threading : 58\n",
            "page : 11310 finish\n",
            "********************\n"
          ]
        }
      ],
      "source": [
        "for i in range(vm_number*per_vm,(vm_number+1)*per_vm):\n",
        "    all_thread[i].start()\n",
        "for i in range(vm_number*per_vm,(vm_number+1)*per_vm):\n",
        "    all_thread[i].join()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DW45cmqeReV2"
      },
      "outputs": [],
      "source": [
        "# all_link[15]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Dh15__OTMY1c"
      },
      "outputs": [],
      "source": [
        "all_link_out = []\n",
        "for i in all_link:\n",
        "    if i != None:\n",
        "        for k in i:\n",
        "            if k != None:\n",
        "                all_link_out.append(k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ghvjWt57vjI9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "156000"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(all_link_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "155751"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(list(set(all_link_out)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "sJ2oqv6EMaLn"
      },
      "outputs": [],
      "source": [
        "all_link_out_array = np.array(all_link_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "QdxqQtbBMp9w"
      },
      "outputs": [],
      "source": [
        "with open(f\"link_data_stack_overflow_python_{vm_number*per_vm}_{(vm_number+1)*per_vm}.pickle\", \"wb\") as f:\n",
        "    pickle.dump(all_link_out_array, f, protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "MjBeSUsB-pn9"
      },
      "outputs": [],
      "source": [
        "all_status_link_out = []\n",
        "for i in all_status_link:\n",
        "    if i != None:\n",
        "        for k in i:\n",
        "            if k != None:\n",
        "                all_status_link_out.append(k)\n",
        "            else : print(\"IsNone\")\n",
        "all_status_link_out_array = np.array(all_status_link_out)\n",
        "with open(f\"status_link_data_stack_overflow_python_{vm_number*per_vm}_{(vm_number+1)*per_vm}.pickle\", \"wb\") as f:\n",
        "    pickle.dump(all_status_link_out_array, f, protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(all_status_link_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(list(set(all_status_link_out)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSXwSKLSMg_W"
      },
      "outputs": [],
      "source": [
        "# with open(\"link_data_stack_overflow_python_2181255.pickle\", \"rb\") as f:\n",
        "#     save_link = pickle.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8sCvYaaLhTU"
      },
      "source": [
        "#Collect code form link"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBSUXZVQK7rP"
      },
      "outputs": [],
      "source": [
        "with open(\"link_data_stack_overflow_python_2181255.pickle\", \"rb\") as f:\n",
        "    save_link = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WPQsgVGK9K7"
      },
      "outputs": [],
      "source": [
        "max_link = len(save_link)\n",
        "max_link = 1000\n",
        "count_thread = 8\n",
        "num_per_thread = max_link//8\n",
        "link_last = max_link%8\n",
        "all_thread = [None]*count_thread\n",
        "code_question = [None]*count_thread\n",
        "code_answer = [None]*count_thread\n",
        "webs = \"https://stackoverflow.com/\"\n",
        "hours = 2\n",
        "minute = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YD_GSD7pLLtV"
      },
      "outputs": [],
      "source": [
        "def save_code_question_answer_all_data(code_question,code_answer,start,stop,number_thread):\n",
        "    try:\n",
        "        st = time.time()\n",
        "        if (code_question[number_thread] or code_answer[number_thread]) != None:\n",
        "            code_answer_in_link = code_answer[number_thread][:start]\n",
        "            code_question_in_link = code_question[number_thread][:start]\n",
        "        else:\n",
        "            code_answer_in_link = []\n",
        "            code_question_in_link = []\n",
        "\n",
        "        replace_code = [['<code>',''],['</code>',''],['&lt;','<'],['&gt;','>'],['&amp;','&'],['&quot;','\"'],['&apos;',\"'\"],['>>> ',''],['... ',''],['...','']]\n",
        "        count = start\n",
        "        for question_link in save_link[start:stop]:\n",
        "            if (time.time() - st) > (hours*60 + minute)*60:\n",
        "                print(f\"-->threading : {number_thread+1}\\nlink : {count} finish with time stop hours : {hours} minute : {minute}\\n{'*'*20}\")\n",
        "                return 0\n",
        "            url_page = webs + question_link\n",
        "            #------------------------------------\n",
        "            while True:\n",
        "                scraper = cloudscraper.create_scraper(delay=10,browser=\"chrome\")\n",
        "                res_page = scraper.get(url)\n",
        "                if res_page.ok:\n",
        "                    #print(f\"Thread : {number_thread} page open\")\n",
        "                    break\n",
        "            html_page = res_page.text\n",
        "            soup_page = BeautifulSoup(html_page ,features=\"html.parser\")\n",
        "            #------------------------------------\n",
        "            if len(soup_page.find_all('a',{'class':'s-pagination--item'}))/2 > 1:\n",
        "                last_page = soup_page.find_all('a',{'class':'s-pagination--item'})[-2].text\n",
        "            else :last_page = 1\n",
        "            code_question_reg = [str(soup_page.find_all('a',{'class':'question-hyperlink'})[0].text)]\n",
        "            code_question_in_link.append(code_question_reg)\n",
        "            answer = []\n",
        "            #------------------------------------\n",
        "            for page_in_question_link in range(int(last_page)):\n",
        "                url_page = webs + question_link + f\"?page={page_in_question_link+1}&tab=scoredesc#tab-top\"\n",
        "                ua = UserAgent()\n",
        "                while True:\n",
        "                    scraper = cloudscraper.create_scraper(delay=10,browser=\"chrome\")\n",
        "                    res_page = scraper.get(url)\n",
        "                    if res_page.ok:\n",
        "                        #print(f\"Thread : {number_thread} page open\")\n",
        "                        break\n",
        "                html_page = res_page.text\n",
        "                soup_page = BeautifulSoup(html_page ,features=\"html.parser\")\n",
        "\n",
        "                answer = soup_page.find_all('div',{'id':'answers'})\n",
        "                # answer = soup_page.find_all('div',{'class':'s-prose'},{'class':'js-post-body'},{'id':'answers'})\n",
        "                # for i_answer in answer:\n",
        "                #     for i_code in i_answer.find_all('code'):\n",
        "                #         if len(str(i_code)) > 50:\n",
        "                #             i_code = str(i_code)\n",
        "                #             for rep in replace_code:\n",
        "                #                 i_code = i_code.replace(rep[0],rep[1])\n",
        "                #             # code_answer.append((((str(i_code).replace('<code>','')).replace('</code>','')).replace('&gt;&gt;&gt; ','')).replace('... ',''))\n",
        "                #             code_answer.append(i_code)\n",
        "                answer.append(answer[0])#*************************\n",
        "\n",
        "            code_answer_in_link.append(answer)#**************************\n",
        "            count += 1\n",
        "            if count%50==0:\n",
        "                print(f\"threading : {number_thread+1}\\nlink : {count}\\nprogress : {((count-start+1)/(stop-start))*100:.2f}%\\n{'*'*20}\")\n",
        "        code_answer[number_thread] = code_answer_in_link\n",
        "        code_question[number_thread] = code_question_in_link\n",
        "        print(f\"-->threading : {number_thread+1}\\nlink : {count} finish\\n{'*'*20}\")\n",
        "    except:\n",
        "        code_answer[number_thread] = code_answer_in_link\n",
        "        code_question[number_thread] = code_question_in_link\n",
        "        print(f\"-->threading : {number_thread+1}\\nlink : {count} loop_interrup_finish\\n{'*'*20}\")\n",
        "        save_code_question_answer_all_data(code_question,code_answer,count,stop,number_thread)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8Y8MnU6LPN8"
      },
      "outputs": [],
      "source": [
        "li = 0\n",
        "for i in range(count_thread):\n",
        "    if i < link_last:\n",
        "        all_thread[i] = threading.Thread(target=save_code_question_answer_all_data,args=(code_question,code_answer,i*num_per_thread + i*(1),(i+1)*num_per_thread + (i+1)*1,i))\n",
        "        li = i\n",
        "        print(i*num_per_thread + i*(1),(i+1)*num_per_thread + (i+1)*1,i)\n",
        "    elif link_last == 0:\n",
        "        all_thread[i] = threading.Thread(target=save_code_question_answer_all_data,args=(code_question,code_answer,i*num_per_thread,(i+1)*num_per_thread,i))\n",
        "        print(i*num_per_thread,(i+1)*num_per_thread,i)\n",
        "    else:\n",
        "        all_thread[i] = threading.Thread(target=save_code_question_answer_all_data,args=(code_question,code_answer,i*num_per_thread + (li+1)*(1),(i+1)*num_per_thread + (li+1)*1,i))\n",
        "        print(i*num_per_thread + (li+1)*(1),(i+1)*num_per_thread + (li+1)*1,i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttIhBMQZLP5W"
      },
      "outputs": [],
      "source": [
        "for i in range(count_thread):\n",
        "    all_thread[i].start()\n",
        "for i in range(count_thread):\n",
        "    all_thread[i].join()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "j8sCvYaaLhTU"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
